{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "tweets_week16september = pd.read_csv(r\"C:\\stage\\project\\datasets\\tweets_week16-09.csv\")\n",
    "\n",
    "# Extract columns from df & perform textblob sentiment analysis\n",
    "tweets_week16september_text = tweets_week16september[\"tweet\"]\n",
    "textblob_tweets = [TextBlob(tweet) for tweet in tweets_week16september_text]\n",
    "sentiment_tweets = [round(tweet.sentiment.polarity,2) for tweet in textblob_tweets]\n",
    "zipped_list = list(zip(tweets_week16september['creation date'], tweets_week16september['tweet'], sentiment_tweets, tweets_week16september['username']))\n",
    "\n",
    "# Store to new dataframe\n",
    "sentiment_df = pd.DataFrame(zipped_list, columns=[\"Creation Date\", \"Tweet\", \"Polarity\", \"Username\"])\n",
    "\n",
    "sentiment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = sentiment_df[\"Polarity\"].value_counts()\n",
    "x = sentiment_count.index\n",
    "y = sentiment_count.values\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.set_palette(\"RdYlGn\")\n",
    "sns.barplot(x, y, alpha=0.8)\n",
    "plt.yticks(np.arange(min(y), max(y), step=10))\n",
    "plt.xticks(plt.xticks()[0], rotation=65)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Amount of tweets\")\n",
    "plt.xlabel(\"Sentiment polarity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'positive'\n",
    "    if polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "sentiments = [get_sentiment(polarity) for polarity in sentiment_df[\"Polarity\"]]\n",
    "\n",
    "sentiment_count_list = np.array([sentiments.count(\"positive\"), sentiments.count(\"neutral\"), sentiments.count(\"negative\")])\n",
    "\n",
    "labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "colors = [\"green\", \"yellow\", \"red\"]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sentiment_count_list, labels=labels, shadow=True, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "ax1.axis('equal') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this sentiment analysis is very basic and not very accurate\n",
    "This analysis would point out that most people who tweet about climate change, have a possitive or neutral sentiment about it. \n",
    "* sentiment polarity < 0 &nbsp;&nbsp;&nbsp; => negative \n",
    "* sentiment polarity > 0 &nbsp;&nbsp;&nbsp; => positive \n",
    "* sentiment polarity = 0 &nbsp;&nbsp;&nbsp; => neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Sentiment analysis with SciKit Learn (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization (reduces words to dictionary root form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "# Read CSV file\n",
    "tweets_week16september = pd.read_csv(r\"C:\\stage\\project\\datasets\\tweets_week16-09.csv\")\n",
    "\n",
    "# Extract tweet column from df\n",
    "tweets_week16september_text = tweets_week16september[\"tweet\"]\n",
    "\n",
    "for tweet in tweets_week16september_text:\n",
    "    document = tweet.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize words, filter stopwords and initialize training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = term frequency, inverse document frequency ()\n",
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.80, stop_words=stopwords.words('english'))\n",
    "processed_features = vectorizer.fit_transform(documents).toarray()\n",
    "X, y = processed_features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
